{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_aa_p1_barcode = pd.read_csv('../../data/Huetal2022/AA_patient_1/GSM5515741_AA1_barcodes.tsv', sep='\\t', header=None)\n",
    "hu_aa_p1_features = pd.read_csv('../../data/Huetal2022/AA_patient_1/GSM5515741_AA1_features.tsv', sep='\\t', header=None)\n",
    "# The data matrix rows are genes and columns are cells. The indices match the indices of the files imported above. Matries are sparse (common in scRNAseq due to dropout)\n",
    "hu_aa_p1_data_mtx = scipy.io.mmread('../../data/Huetal2022/AA_patient_1/GSM5515741_AA1_matrix.mtx')\n",
    "hu_aa_p1_data_df = pd.DataFrame.sparse.from_spmatrix(hu_aa_p1_data_mtx)\n",
    "hu_aa_p1_data = { \"cells\": hu_aa_p1_barcode, \"genes\": hu_aa_p1_features, \"data\":hu_aa_p1_data_df}\n",
    "hu_aa_p2_barcode = pd.read_csv('../../data/Huetal2022/AA_patient_2/GSM5515742_AA2_barcodes.tsv', sep='\\t', header=None)\n",
    "hu_aa_p2_features = pd.read_csv('../../data/Huetal2022/AA_patient_2/GSM5515742_AA2_features.tsv', sep='\\t', header=None)\n",
    "hu_aa_p2_data_mtx = scipy.io.mmread('../../data/Huetal2022/AA_patient_2/GSM5515742_AA2_matrix.mtx')\n",
    "hu_aa_p2_data_df = pd.DataFrame.sparse.from_spmatrix(hu_aa_p2_data_mtx)\n",
    "hu_aa_p2_data = { \"cells\": hu_aa_p2_barcode, \"genes\": hu_aa_p2_features, \"data\":hu_aa_p2_data_df}\n",
    "hu_n_p1_barcode = pd.read_csv('../../data/Huetal2022/N_patient_1/GSM5515743_Normal1_barcodes.tsv', sep='\\t', header=None)\n",
    "hu_n_p1_features = pd.read_csv('../../data/Huetal2022/N_patient_1/GSM5515743_Normal1_features.tsv', sep='\\t', header=None)\n",
    "hu_n_p1_data_mtx = scipy.io.mmread('../../data/Huetal2022/N_patient_1/GSM5515743_Normal1_matrix.mtx')\n",
    "hu_n_p1_data_df = pd.DataFrame.sparse.from_spmatrix(hu_n_p1_data_mtx)\n",
    "hu_n_p1_data = { \"cells\": hu_n_p1_barcode, \"genes\": hu_n_p1_features, \"data\":hu_n_p1_data_df}\n",
    "hu_n_p2_barcode = pd.read_csv('../../data/Huetal2022/N_patient_2/GSM5515744_Normal2_barcodes.tsv', sep='\\t', header=None)\n",
    "hu_n_p2_features = pd.read_csv('../../data/Huetal2022/N_patient_2/GSM5515744_Normal2_features.tsv', sep='\\t', header=None)\n",
    "hu_n_p2_data_mtx = scipy.io.mmread('../../data/Huetal2022/N_patient_2/GSM5515744_Normal2_matrix.mtx')\n",
    "hu_n_p2_data_df = pd.DataFrame.sparse.from_spmatrix(hu_n_p2_data_mtx)\n",
    "hu_n_p2_data = { \"cells\": hu_n_p2_barcode, \"genes\": hu_n_p2_features, \"data\":hu_n_p2_data_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add col for disease status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genes as cols, cells as rows\n",
    "hu_aa_p1_data_df = hu_aa_p1_data_df.T\n",
    "hu_aa_p2_data_df = hu_aa_p2_data_df.T\n",
    "hu_n_p1_data_df = hu_n_p1_data_df.T\n",
    "hu_n_p2_data_df = hu_n_p2_data_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add col for disease status\n",
    "hu_aa_p1_data_df['Aplastic Anemia'] = 1\n",
    "hu_aa_p2_data_df['Aplastic Anemia'] = 1\n",
    "hu_n_p1_data_df['Aplastic Anemia'] = 0\n",
    "hu_n_p2_data_df['Aplastic Anemia'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = pd.concat([hu_aa_p1_data_df, hu_aa_p2_data_df, hu_n_p1_data_df, hu_n_p2_data_df])\n",
    "full_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = full_dataset['Aplastic Anemia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_no_labels = full_dataset.drop('Aplastic Anemia', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(full_data_no_labels, labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find singular values\n",
    "from scipy.linalg import svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD\n",
    "U, s, VT = svd(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to not have to run again in the future\n",
    "U.tofile('trainingU.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.tofile('trainings.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VT.tofile('trainingVT.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = X_train.index\n",
    "type(list(X_train_indices))\n",
    "with open(\"X_train_idxs.txt\", \"w\") as output:\n",
    "    output.write(str(list(X_train_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(\"ytrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine number of modes to incorperate\n",
    "energyThreshold = .9\n",
    "normalized_eigvals = s / sum(s)\n",
    "normalized_eigvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumEnergy = np.cumsum(s)/sum(s)\n",
    "cumEnergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energyIndex = np.argwhere(cumEnergy > energyThreshold)\n",
    "energyIndex = int(min(energyIndex))\n",
    "energyIndex # use rank 1939 to get 90% of energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project onto determined number or modes\n",
    "rankVT = VT[:, 1:energyIndex]\n",
    "rankVT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = rankVT.T.dot(X_test.T)\n",
    "training = rankVT.T.dot(X_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using LDA\n",
    "group = y_train\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = LDA()\n",
    "clf.fit(training.T, group)\n",
    "LDA(priors=None, shrinkage=None, solver='svd',\n",
    "  store_covariance=False, tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predictions = clf.predict(sample.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_predictions = sum(y_test_predictions == y_test.to_numpy())\n",
    "num_correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_incorrect_predictions = len(y_test) - num_correct_predictions\n",
    "num_incorrect_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_correct = num_correct_predictions/len(y_test)\n",
    "percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~95% success rate on this test set, lets try on training data\n",
    "y_training_predictions = clf.predict(training.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_predictions = sum(y_training_predictions == group.to_numpy())\n",
    "num_correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_incorrect_predictions = len(group.to_numpy()) - num_correct_predictions\n",
    "num_incorrect_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_correct = num_correct_predictions/len(group.to_numpy())\n",
    "percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about 97% correct\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we know the number of components to use, lets try just an LDA call from the start\n",
    "clf2 = LDA()\n",
    "clf2.fit(X_train.to_numpy(), y_train)\n",
    "LDA(priors=None, shrinkage=None, solver='svd',\n",
    "  store_covariance=False, tol=0.0001, n_components = energyIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions2 = clf2.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions2 = clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_train_predictions_2 = sum(training_predictions2 == y_train.to_numpy())\n",
    "percent_correct = num_correct_train_predictions_2/len(y_train)\n",
    "percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct_test_predictions_2 = sum(test_predictions2 == y_test.to_numpy())\n",
    "percent_correct = num_correct_test_predictions_2/len(y_test)\n",
    "percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 57% that makes a lot more sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_aa_p1_data_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
